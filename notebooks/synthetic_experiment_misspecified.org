#+SETUPFILE: ~/life/references/templates/org/literate_programming_setupfile.org
#+SETUPFILE: ~/life/references/templates/org/maths_setupfile.org
#+PROPERTY: header-args :kernel meta_learning :tangle yes :resuls output
#+LATEX_HEADER_EXTRA: \setmainfont{Libre Baskerville}

* Introduction
:LOGBOOK:
CLOCK: [2020-05-14 Thu 17:46]
CLOCK: [2020-05-14 Thu 17:16]--[2020-05-14 Thu 17:38] =>  0:22
CLOCK: [2020-05-12 Tue 15:51]--[2020-05-12 Tue 16:16] =>  0:25
CLOCK: [2020-05-12 Tue 13:27]--[2020-05-12 Tue 13:52] =>  0:25
CLOCK: [2020-05-12 Tue 11:57]--[2020-05-12 Tue 12:22] =>  0:25
:END:
Look at how the KNN works on a misspecified dataset, we have 2nd order datasets
going through the origin.

Import necessary libraries
#+begin_src jupyter-python
import os
from pathlib import Path
import re

from loguru import logger
import numpy as np
from scipy.spatial.distance import pdist, squareform
from sklearn.decomposition import KernelPCA
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import ParameterGrid
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import hickle as kl
from torch.utils.data import DataLoader

# AML imports
from active_meta_learning.data import (
    EnvironmentDataSet,
    UniformSphere,
    HypercubeWithKVertexGaussian,
    VonMisesFisherMixture,
)
from active_meta_learning.data_utils import (
    aggregate_sampled_task_batches,
    coalesce_train_and_test_in_dicts,
    convert_batches_to_fw_form,
    convert_batches_to_np,
    get_task_parameters,
    remove_batched_dimension_in_D,
    reorder_list,
    set_random_seeds,
    form_datasets_from_tasks,
    npfy_batches,
)
from active_meta_learning.kernels import (
    gaussian_kernel_matrix,
    gaussian_kernel_mmd2_matrix,
    median_heuristic,
    mmd2,
)
from active_meta_learning.optimisation import KernelHerding
from active_meta_learning.estimators import (
    RidgeRegression,
    BiasedRidgeRegression,
    RidgeRegPrototypeEstimator,
    TrueWeightPrototypeEstimator,
    GDLeastSquares,
)
#+end_src

#+RESULTS:

* Functions
Additional functions which will be use
** Plotting
#+begin_src jupyter-python
def plot_task_weights(tasks, ax):
    ws = get_task_parameters(tasks)
    ax.scatter(ws[:, 0], ws[:, 1])
    return ax

def plot_kh_weights(kh_w, kh_D, train_tasks, until_t=10):
    ws = get_task_parameters(train_tasks)
    ws = KernelPCA(n_components=2, kernel="rbf").fit_transform(ws)
    fig, ax = plt.subplots(1, 3, figsize=(4 * 3, 4))
    bbox = dict(boxstyle="round", fc="0.8")
    # kh_w
    ax[0].scatter(ws[:, 0], ws[:, 1], alpha=0.2, color="black")
    ws_w = ws[kh_w.sampled_order[:until_t]]
    ax[0].scatter(ws_w[:until_t, 0], ws_w[:until_t, 1], color="red")
    for i in range(until_t):
        ax[0].annotate(i+1, (ws_w[i, 0], ws_w[i, 1]), bbox=bbox, size=10)
    ax[0].set_title("First {} chosen point (KH weights)".format(until_t))

    # kh_D
    ax[1].scatter(ws[:, 0], ws[:, 1], alpha=0.2, color="black")
    ws_D = ws[kh_D.sampled_order[:until_t]]
    ax[1].scatter(ws_D[:until_t, 0], ws_D[:until_t, 1], color="red")
    for i in range(until_t):
        ax[1].annotate(i+1, (ws_D[i, 0], ws_D[i, 1]), bbox=bbox, size=10)
    ax[1].set_title("First {} chosen point (KH data)".format(until_t))

    # No reordering
    ax[2].scatter(ws[:, 0], ws[:, 1], alpha=0.2, color="black")
    ws_u = ws[np.random.permutation(ws.shape[0])[:until_t]]
    ax[2].scatter(ws_u[:until_t, 0], ws_u[:until_t, 1], color="red")
    for i in range(until_t):
        ax[2].annotate(i+1, (ws_u[i, 0], ws_u[i, 1]), bbox=bbox, size=10)
    ax[2].set_title("First {} chosen point (Random)".format(until_t))
    plt.tight_layout()

    return ax

def gen_3d_ax():
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    return fig, ax

def plot_task_lin_reg(task, ax):
    X_tr, y_tr = task["train"]
    X_tr = KernelPCA(n_components=2, kernel="rbf").fit_transform(X_tr)
    X_te, y_te = task["test"]
    X_te = KernelPCA(n_components=2, kernel="rbf").fit_transform(X_te)
    # train
    ax.scatter(X_tr[:, 0], X_tr[:, 1], y_tr, c="blue", label="train set")
    # test
    ax.scatter(X_te[:, 0], X_te[:, 1], y_te, c="red", label="test set")
    ax.legend()
    return ax

def plot_aml_ci(ax, error, color, label, until_t):
    mean = error.mean(axis=1)
    std = np.std(error, axis=1)
    ax.plot(mean[:until_t], label=label, color=color)
    upper_ci = mean + std
    lower_ci = mean - std
    ax.fill_between(
        np.arange(until_t),
        lower_ci[:until_t],
        upper_ci[:until_t],
        color=color,
        alpha=0.2,
    )

def plot_itl_ci(ax, error, color, label, until_t):
    mean = np.mean(error)
    std = np.std(error)
    ax.axhline(mean, label=label, color=color, linestyle="--")
    upper_ci = mean + std
    lower_ci = mean - std
    ax.fill_between(
        np.arange(until_t), lower_ci, upper_ci, color=color, alpha=0.2
    )

def plot_hist_with_ci(data, ax, n_std=1):
    mean = np.mean(data)
    std = np.std(data)
    lci = mean - n_std * std
    uci = mean + n_std * std
    ax.hist(data)
    ax.axvline(mean, color="red")
    ax.axvline(lci, color="red", alpha=0.4)
    ax.axvline(uci, color="red", alpha=0.4)

def get_ci(matrix):
    # row is time, columns are runs
    mean = np.mean(matrix, axis=1)
    std = np.std(matrix, axis=1)
    return mean, mean - std, mean + std
#+end_src

#+RESULTS:

** Data
#+begin_src jupyter-python
def y_func_2nd_order(X, w):
    return (X @ w) * (X @ w + 1)

def generate_data(env, noise_w, noise_y, k_shot, k_query, num_train_tasks=100, num_val_tasks=100, num_test_tasks=100, y_func=y_func_2nd_order):
    env_dataset = EnvironmentDataSet(k_shot, k_query, env, noise_w, noise_y, y_func)
    dataloader = DataLoader(
        env_dataset, collate_fn=env_dataset.collate_fn, batch_size=1,
    )
    # Train data
    train_tasks = aggregate_sampled_task_batches(dataloader, num_train_tasks)
    train_tasks_kh = convert_batches_to_fw_form(train_tasks)
    train_tasks = npfy_batches(train_tasks)

    # Val data
    val_tasks = aggregate_sampled_task_batches(dataloader, num_val_tasks)
    val_tasks_kh = convert_batches_to_fw_form(val_tasks)
    val_tasks = npfy_batches(val_tasks)

    # Test data
    test_tasks = aggregate_sampled_task_batches(dataloader, num_test_tasks)
    test_tasks_kh = convert_batches_to_fw_form(test_tasks)
    test_tasks = npfy_batches(test_tasks)
    return train_tasks, train_tasks_kh, val_tasks, val_tasks_kh, test_tasks, test_tasks_kh

def _mmd2_matrix(A, B, base_s2):
    assert len(A.shape) == 3
    m, n, d = A.shape
    assert len(B.shape) == 3
    p, q, l = B.shape
    M2 = np.zeros((m, p))
    for i in range(m):
        for j in range(p):
            K_xx = gaussian_kernel_matrix(A[i], s2=base_s2)
            K_yy = gaussian_kernel_matrix(B[j], s2=base_s2)
            K_xy = gaussian_kernel_matrix(A[i], B[j], s2=base_s2)
            M2[i, j] = mmd2(K_xx, K_yy, K_xy)
    return M2

def _gaussian_kernel_mmd2_matrix(A, B, base_s2, meta_s2):
    """Calculate the double gaussian kernel

    Calculate the double gaussian kernel matrix between A and B
    using base_s2 for the inner and meta_s2 for the outer level
    """
    M2 = _mmd2_matrix(A, B, base_s2)
    return np.exp(-0.5 * M2 / meta_s2)

def calculate_double_gaussian_median_heuristics(
    A, n_base_subsamples=None, n_meta_subsamples=None
):
    """A.shape = (m, n, d), m is number of datasets, n is the size, d is the dimension"""
    assert len(A.shape) == 3
    m, n, d = A.shape
    if n_base_subsamples is None:
        vec_A = A.reshape(-1, d)
        pairwise_square_dists = squareform(pdist(vec_A, "sqeuclidean"))
    else:
        vec_A = A.reshape(-1, d)
        subsample_indices = np.random.permutation(vec_A.shape[0])[:n_base_subsamples]
        vec_A = vec_A[subsample_indices]
        pairwise_square_dists = squareform(pdist(vec_A, "sqeuclidean"))
    base_s2 = median_heuristic(pairwise_square_dists)
    M2 = np.zeros((m, m))
    for i in range(m):
        for j in range(i):
            K_xx = gaussian_kernel_matrix(A[i], s2=base_s2)
            # K_xx = K_xx + np.eye(n)*eps
            K_yy = gaussian_kernel_matrix(A[j], s2=base_s2)
            # K_yy = K_yy + np.eye(n)*eps
            K_xy = gaussian_kernel_matrix(A[i], A[j], s2=base_s2)
            M2[i, j] = mmd2(K_xx, K_yy, K_xy)
    # Only have lower diagonal entries and diag=0
    # this way we avoid computing m(m-1)/2 entries
    M2 = M2 + M2.T
    meta_s2 = median_heuristic(M2, n_meta_subsamples)

    return base_s2, meta_s2
#+end_src

#+RESULTS:

** Meta-learning
:LOGBOOK:
CLOCK: [2020-05-13 Wed 15:37]--[2020-05-13 Wed 16:02] =>  0:25
:END:
#+begin_src jupyter-python
class IndependentTaskLearning:
    def __init__(self, tasks, algorithm, loss=mean_squared_error):
        """
        :param tasks: tasks that ITL will be performed over by algorithm
        :type tasks: list of tasks, where each task is a dict with keys ("train", "test")
            and values (X_tr, y_tr), tuple of numpy arrays
        :param algorithm: algorithm implementing sklearn fit / predict framework
        :type algorithm: instance of predictor class with fit / predict defined
        :param loss: loss function taking loss(y, y_pred)
        :type loss: loss(y: np.ndarray, y_pred: np.ndarray) -> float
        """
        self.tasks = tasks
        self.algorithm = algorithm
        self.loss = loss

    def fit(self, task):
        """Fit `algorithm` to the i'th task"""
        X_tr, y_tr = task["train"]
        self.algorithm.fit(X_tr, y_tr)

    def predict(self, task):
        X_te, _ = task["test"]
        return self.algorithm.predict(X_te)

    def get_loss(self, task):
        _, y_te = task["test"]
        self.fit(task)
        y_pred = self.predict(task)
        return self.loss(y_pred, y_te)

    def calculate_transfer_risk(self):
        # Collect loss for each task in tasks
        self.losses_ = []
        self.weights_ = []
        for task in self.tasks:
            self.losses_.append(self.get_loss(task))
            self.weights_.append(self.algorithm.w_hat_)
        self.losses_ = np.array(self.losses_)
        self.weights_ = np.array(self.weights_)

    def set_params(self, params):
        """Update paramaters of algorithm"""
        self.algorithm.set_params(**params)

    def get_params(self):
        """Update paramaters of algorithm"""
        return self.algorithm.get_params()

def cross_validate_itl(itl, cv_params):
    """Cross validate itl over cv_params

    itl is an object of class IndependentTaskLearning
    and cv_params is a dictionary of the values for each
    parameter."""
    param_grid = ParameterGrid(cv_params)
    opt_loss = np.inf
    opt_params = None
    for params in param_grid:
        logger.info("Cross validating params: {}".format(params))
        itl.set_params(params)
        itl.calculate_transfer_risk()
        current_loss = np.mean(itl.losses_)
        logger.info("Current loss: {}".format(current_loss))
        if current_loss < opt_loss:
            opt_loss = current_loss
            opt_params = params
            logger.info(
                "Best params so far {}, with loss {:.4f}".format(params, opt_loss)
            )
    return opt_params, opt_loss


class MetaKNNExperiment:
    """Full experiment optimised for speed

    This does not adhere to the sklearn like
    fit/transform/predict framework."""

    def __init__(
        self,
        train_tasks,
        test_tasks,
        dist_tr_te,
        base_algorithm,
        k_nn,
        train_task_reordering,
        prototype_estimator,  # transformer prototype
    ):
        self.train_tasks = train_tasks
        self.test_tasks = test_tasks
        self.dist_tr_te = dist_tr_te
        self.base_algorithm = base_algorithm
        self.k_nn = k_nn
        self.train_task_reordering = train_task_reordering
        self.prototype_estimator = prototype_estimator
        self.d = self.train_tasks[0]["w"].shape[0]

        self.T_tr, self.T_te = len(train_tasks), len(test_tasks)
        assert self.dist_tr_te.shape == (self.T_tr, self.T_te)
        self._reorder()
        self._form_datasets_from_tasks()
        self.calculate_prototypes()

    def _reorder(self):
        self.train_tasks = [self.train_tasks[i] for i in self.train_task_reordering]
        self.dist_tr_te = self.dist_tr_te[
            np.ix_(self.train_task_reordering, np.arange(self.T_te))
        ]

    def _form_datasets_from_tasks(self):
        self.train_datasets = form_datasets_from_tasks(self.train_tasks)
        self.test_datasets = form_datasets_from_tasks(self.test_tasks)
        self.datasets = np.concatenate(
            [self.train_datasets, self.test_datasets], axis=0
        )

    def calculate_prototypes(self):
        """Recalculate prototypes using prototype_estimator

        This allows us to cross-validate after we change the prototype
        estimator parameters"""
        self.prototypes = self.prototype_estimator.transform(self.train_tasks)

    def _adapt(self, i, t):
        """Adapt to one task with index i when meta-train set is of size t"""
        test_task = self.test_tasks[i]
        X_tr, y_tr = test_task["train"]
        distances = self.dist_tr_te[:t, i]

        knn_prototypes = self.prototypes[np.argsort(distances)[: self.k_nn], :]

        w_0 = np.mean(knn_prototypes, axis=0)
        self.w_0_[t, i] = w_0
        self.base_algorithm.fit(X_tr, y_tr, w_0=w_0)
        self.w_hat_[t, i] = self.base_algorithm.w_hat_

    def _loss(self, i, t):
        test_task = self.test_tasks[i]
        X_te, y_te = test_task["test"]
        self._adapt(i, t)
        return mean_squared_error(y_te, self.base_algorithm.predict(X_te))

    def calculate_transfer_risk(self):
        """Calculate the transfer risk"""
        # The loss matrix is a matrix of size (T_tr, T_te)
        # Note that the first self.k_nn columns are nans selfince
        # we do not fill them in as not eno ugh prototypes are available
        self.loss_matrix_ = np.zeros((self.T_tr, self.T_te))
        self.loss_matrix_[: self.k_nn, :] = np.nan
        # Additional info
        self.w_0_ = np.zeros((self.T_tr, self.T_te, self.d))
        self.w_hat_ = np.zeros((self.T_tr, self.T_te, self.d))
        # Each t represents using meta-train instances up until t according to
        # ordering as prototypes. We need to start at k_nn to be able to find
        # k_nn neighbours
        for t in range(self.k_nn, self.T_tr):
            for i in range(self.T_te):
                self.loss_matrix_[t, i] = self._loss(i, t)

    def set_base_algorithm_params(self, params):
        self.base_algorithm.set_params(**params)

    def get_base_algorithm_params(self):
        return self.base_algorithm.get_params()

    def set_prototype_estimator_params(self, params):
        self.prototype_estimator.set_params(**params)

    def get_prototype_estimator_params(self):
        return self.prototype_estimator.get_params()

    def set_params(self, params):
        # Need to catch estimator having no params
        self.set_base_algorithm_params(params["base_algorithm"])
        self.set_prototype_estimator_params(params["prototype_estimator"])

    def get_params(self):
        return {
            "base_algorithm": self.get_base_algorithm_params(),
            "prototype_estimator": self.get_prototype_estimator_params(),
        }
#+end_src

#+RESULTS:

* Hypersphere
:LOGBOOK:
CLOCK: [2020-05-13 Wed 16:14]--[2020-05-13 Wed 16:39] =>  0:25
CLOCK: [2020-05-12 Tue 20:26]--[2020-05-12 Tue 20:51] =>  0:25
CLOCK: [2020-05-12 Tue 14:41]--[2020-05-12 Tue 15:06] =>  0:25
CLOCK: [2020-05-12 Tue 14:10]--[2020-05-12 Tue 14:35] =>  0:25
:END:
All the data generated on the hypersphere.

#+begin_src jupyter-python
y_func_misspec = y_func_2nd_order

def generate_hypersphere_data(
    d, noise_w, noise_y, k_shot, k_query, num_train_tasks=100, num_val_tasks=100, num_test_tasks=100
):
    env = UniformSphere(d)
    return generate_data(env, noise_w, noise_y, k_shot, k_query, num_train_tasks, num_val_tasks, num_test_tasks, y_func_misspec)

d = 2
noise_w, noise_y = 0.0, 0.0
k_shot, k_query = 20, 25
n_tr, n_val, n_te = 50, 80, 100
train_tasks, train_tasks_kh, val_tasks, val_tasks_kh, test_tasks, test_tasks_kh = generate_hypersphere_data(d, noise_w, noise_y, k_shot, k_query, n_tr, n_val, n_te)
train_datasets = form_datasets_from_tasks(train_tasks)
val_datasets = form_datasets_from_tasks(val_tasks)
test_datasets = form_datasets_from_tasks(test_tasks)

train_ws = get_task_parameters(train_tasks)
val_ws = get_task_parameters(val_tasks)
test_ws = get_task_parameters(test_tasks)
#+end_src

#+RESULTS:

Plotting the weights
#+begin_src jupyter-python
fig, ax = plt.subplots(1, 1, figsize=(10, 10))
plot_task_weights(train_tasks, ax)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.axes._subplots.AxesSubplot at 0x7fc426ded490>
[[file:./.ob-jupyter/d63685c1063eae95c2e2845e2c29f26b29c998b6.png]]
:END:

Plot of the actual linear regression datasets generated. We pick 3 random tasks
which differ
#+begin_src jupyter-python
fig = plt.figure(figsize=(8, 16))
axes = [fig.add_subplot(3, 1, i, projection="3d") for i in range(1, 4)]
rand_idx = np.random.permutation(20)
for i, ax in enumerate(axes):
    task = train_tasks[rand_idx[i]]
    plot_task_lin_reg(task, ax)
    w = task["w"]
    ax.set_title("w: ({:.2f}, {:.2f})".format(w[0], w[1]))
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 460
[[file:./.ob-jupyter/bad1c63bc9b6235b1699f51329ce3cef2a40d147.png]]
:END:

From the above plot we can see how they differ, since we are assuming a linear
regression setup the points all lie on hyperspheres.

Now we consider how the different KH methods pick points.
#+begin_src jupyter-python
# KH on data
base_s2_D, meta_s2_D = calculate_double_gaussian_median_heuristics(
    train_datasets, n_base_subsamples=200
)
K_D = _gaussian_kernel_mmd2_matrix(
    A=train_datasets, B=train_datasets, base_s2=base_s2_D, meta_s2=meta_s2_D
)
# KH on weights
train_task_ws = get_task_parameters(train_tasks)
ws_dataset = train_task_ws[:, np.newaxis, :]
base_s2_w, meta_s2_w = calculate_double_gaussian_median_heuristics(
    ws_dataset, n_base_subsamples=200
)
K_w = _gaussian_kernel_mmd2_matrix(
    A=ws_dataset, B=ws_dataset, base_s2=base_s2_w, meta_s2=meta_s2_w
)
#+end_src

#+RESULTS:

Investigate how the kernel matrix look like.
#+begin_src jupyter-python
fig, ax = plt.subplots()
ax.imshow(K_D, vmin=0.0, vmax=1.0)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.image.AxesImage at 0x7fc4261d02d0>
#+attr_org: :width 252
[[file:./.ob-jupyter/3c2e281f3cab464d5cc7ae8661c1bd65919705ad.png]]
:END:

#+begin_src jupyter-python
fig, ax = plt.subplots()
ax.imshow(K_w, vmin=0.0, vmax=1.0)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.image.AxesImage at 0x7fc426183250>
#+attr_org: :width 252
[[file:./.ob-jupyter/520a0698a7cbd91571b5238b5d4a0ca311e17dd6.png]]
:END:

#+begin_src jupyter-python
fig, ax = plt.subplots()
_ = ax.hist((K_w - K_D)[np.triu_indices(n_tr, k=1)], range=(-1.0, 1.0), density=True)
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 373
[[file:./.ob-jupyter/1bc39c1e71fda5e9fa012b0a4c35b0b04e365683.png]]
:END:

Looks pretty nice above, the weights and data dataset kernel matrix seem to find
something reasonable as the difference is not too unlike.

Running the actual kernel herding algorithms
#+begin_src jupyter-python
kh_D = KernelHerding(K_D)
kh_D.run()
kh_w = KernelHerding(K_w)
kh_w.run()
#+end_src

#+RESULTS:


#+begin_src jupyter-python
plot_kh_weights(kh_w, kh_D, train_tasks, until_t=20)
#+end_src

#+RESULTS:
:RESULTS:
: array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fc426052390>,
:        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc425fff390>,
:        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc425fafb10>],
:       dtype=object)
[[file:./.ob-jupyter/5f5a8ceebab30af0cf68ede5264d1d9def45d339.png]]
:END:

** KNN Meta learning
:LOGBOOK:
CLOCK: [2020-05-13 Wed 17:48]--[2020-05-13 Wed 18:13] =>  0:25
:END:
We run KNN meta learning on the dataset to see and understand what works where.
We consider
- Uniform
- KH on data
- KH on weights
and we use the true weights. Alternatively, we will shrink the true weights to
see how that impacts (and possibly make it better than using the true weights).
This is due to the observed phenomenon where the ridge weights perform better
than the true weights.

Calculate the mmd distances from all the train to test tasks. These are used
later when we use the KNN algorithm
#+begin_src jupyter-python
train_datasets = form_datasets_from_tasks(train_tasks)
# Don't cheat, can only use support/train set for meta-test and meta-val
# tr_val_datasets = form_datasets_from_tasks(val_tasks, use_only_train=True)
tr_test_datasets = form_datasets_from_tasks(test_tasks, use_only_train=True)
# M_tr_val_D = np.sqrt(_mmd2_matrix(train_datasets, tr_val_datasets, base_s2_D))
M_tr_te_D = np.sqrt(_mmd2_matrix(train_datasets, tr_test_datasets, base_s2_D))
#+end_src

#+RESULTS:

We have two things to set, \(\alpha_{RR}, \alpha_{prot}\) for the regularisation
parameter in Ridge Regression and Prototypes.
#+begin_src jupyter-python
alpha_rrs = np.geomspace(1e-6, 3, 10)
alpha_prot = 0.001
#+end_src

#+RESULTS:

** ITL Ridge Reg
Evaluate ridge regression in an independent task learning setting
#+begin_src jupyter-python
rr = RidgeRegression(alpha=0.0001)
itl_rr = IndependentTaskLearning(train_tasks, rr)
itl_rr_opt_params, itl_rr_cross_val_loss = cross_validate_itl(
    itl_rr, {"alpha": alpha_rrs.tolist()}
)
itl_rr.set_params(itl_rr_opt_params)
itl_rr.tasks = test_tasks
itl_rr.calculate_transfer_risk()
#+end_src

#+RESULTS:
#+begin_example
2020-05-14 18:07:36.921 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 1e-06}
2020-05-14 18:07:36.962 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.0187374901071508
2020-05-14 18:07:36.963 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 1e-06}, with loss 0.0187
2020-05-14 18:07:36.966 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 5.244210785953468e-06}
2020-05-14 18:07:37.012 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.0187374995783169
2020-05-14 18:07:37.013 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 2.7501746767510743e-05}
2020-05-14 18:07:37.061 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.018737549266497403
2020-05-14 18:07:37.063 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.0001442249570307409}
2020-05-14 18:07:37.113 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.018737810374916
2020-05-14 18:07:37.115 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.0007563460752642876}
2020-05-14 18:07:37.158 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.018739194328885364
2020-05-14 18:07:37.158 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.0039664382458145546}
2020-05-14 18:07:37.199 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.018746852648290752
2020-05-14 18:07:37.200 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.02080083823051906}
2020-05-14 18:07:37.234 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.01879771770671653
2020-05-14 18:07:37.236 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.10908398020536153}
2020-05-14 18:07:37.291 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.019319076751328275
2020-05-14 18:07:37.292 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.5720593855676914}
2020-05-14 18:07:37.347 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.02576520724805749
2020-05-14 18:07:37.348 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 3.0}
2020-05-14 18:07:37.419 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.07353782055472224
#+end_example

The train loss
#+begin_src jupyter-python
fig, ax = plt.subplots()
sns.distplot(itl_rr.losses_, kde=True, rug=True, ax=ax)
ax.axvline(itl_rr.losses_.mean(), color="red", linestyle="--")
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.lines.Line2D at 0x7fc4241a38d0>
#+attr_org: :width 370
[[file:./.ob-jupyter/6d60bdaf5d2580bbc247de19ed32c7f1e9207220.png]]
:END:

** Meta-learning setup
:LOGBOOK:
CLOCK: [2020-05-13 Wed 18:49]--[2020-05-13 Wed 19:14] =>  0:25
:END:
Now we proceed to do active meta learning. We will reorder the sequences
according to KH on weights and data. As the actual meta learning algorithm we
will use the KNN on datasets and use the biased ridge regression. We will reuse
the optimal alpha from ITL with ridge reg. From here on we split into two cases,
where for the prototype estimator we use
- Ridge Regression
- True Weights

we use 3 for the number of nearest neighbours
#+begin_src jupyter-python
k_nn = 3
#+end_src

#+RESULTS:

*** Biased Ridge Reg
:LOGBOOK:
CLOCK: [2020-05-13 Wed 19:34]--[2020-05-13 Wed 19:59] =>  0:25
:END:
#+begin_src jupyter-python
aml_order = kh_D.sampled_order
biased_rr = BiasedRidgeRegression(alpha=itl_rr_opt_params["alpha"])
model = MetaKNNExperiment(
    train_tasks,
    test_tasks,
    M_tr_te_D,
    biased_rr,
    k_nn,
    aml_order,
    RidgeRegPrototypeEstimator(alpha=alpha_prot),
)
model.calculate_transfer_risk()
#+end_src

#+RESULTS:

Let's look at how this evolved over time, and compare it with the ITL baseline
#+begin_src jupyter-python
fig, ax = plt.subplots()
t = np.arange(model.loss_matrix_.shape[0])
plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
ax.axhline(noise_y, color="black")
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example

ValueErrorTraceback (most recent call last)
<ipython-input-50-d731671adbc0> in <module>
      1 fig, ax = plt.subplots()
      2 t = np.arange(model.loss_matrix_.shape[0])
----> 3 plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
      4 plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
      5 ax.axhline(noise_y, color="black")

<ipython-input-32-5428848ec3b9> in plot_aml_ci(ax, error, color, label, until_t)
     64         upper_ci[:until_t],
     65         color=color,
---> 66         alpha=0.2,
     67     )
     68

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs)
   1597     def inner(ax, *args, data=None, **kwargs):
   1598         if data is None:
-> 1599             return func(ax, *map(sanitize_sequence, args), **kwargs)
   1600
   1601         bound = new_sig.bind(ax, *args, **kwargs)

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/axes/_axes.py in fill_between(self, x, y1, y2, where, interpolate, step, **kwargs)
   5242             where = True
   5243         where = where & ~functools.reduce(np.logical_or,
-> 5244                                           map(np.ma.getmask, [x, y1, y2]))
   5245
   5246         x, y1, y2 = np.broadcast_arrays(np.atleast_1d(x), y1, y2)

ValueError: operands could not be broadcast together with shapes (100,) (50,)
#+end_example
#+attr_org: :width 373
[[file:./.ob-jupyter/25299b62ef25cf02586d8fccc9e8a83044aed3d2.png]]
:END:

#+begin_src jupyter-python
zero_vs_ws = np.linalg.norm(test_ws, axis=1)
itl_vs_ws = np.linalg.norm(itl_rr.weights_ - test_ws, axis=1)
aml_w0_vs_ws = np.linalg.norm(model.w_0_[-1, :] - test_ws, axis=1)
aml_w_hat_vs_ws = np.linalg.norm(model.w_hat_[-1, :] - test_ws, axis=1)

fig, ax = plt.subplots(4, 1, sharex=True)
plot_hist_with_ci(zero_vs_ws, ax[0])
plot_hist_with_ci(itl_vs_ws, ax[1])
plot_hist_with_ci(aml_w0_vs_ws, ax[2])
plot_hist_with_ci(aml_w_hat_vs_ws, ax[3])
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 370
[[file:./.ob-jupyter/2495f9728e23df795e8186d035a04d8b2a21ed79.png]]
:END:

I want to test the hypothesis of shrinkage. Let's compare the sizes of the
resulting \(w_{0}\) and \(\hat{w}\)
#+begin_src jupyter-python
fig, ax = plt.subplots()
ax.hist(np.linalg.norm(model.prototypes, axis=1))
#+end_src

#+RESULTS:
:RESULTS:
| array | ((23 2 1 0 1 4 19)) | array | ((0.11905558 0.38412599 0.6491964 0.91426681 1.17933722 1.44440763 1.70947804 1.97454845)) | <a | list | of | 7 | Patch | objects> |
#+attr_org: :width 370
[[file:./.ob-jupyter/3e0c6584025af58e959567640a7b573ec4319cdb.png]]
:END:

*** True weights
:LOGBOOK:
CLOCK: [2020-05-13 Wed 19:34]--[2020-05-13 Wed 19:59] =>  0:25
:END:
#+begin_src jupyter-python
aml_order = kh_D.sampled_order
biased_rr = BiasedRidgeRegression(alpha=itl_rr_opt_params["alpha"])
model = MetaKNNExperiment(
    train_tasks,
    test_tasks,
    M_tr_te_D,
    biased_rr,
    k_nn,
    aml_order,
    TrueWeightPrototypeEstimator(),
)
model.calculate_transfer_risk()
#+end_src

#+RESULTS:

Let's look at how this evolved over time, and compare it with the ITL baseline
#+begin_src jupyter-python
fig, ax = plt.subplots()
t = np.arange(model.loss_matrix_.shape[0])
plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
ax.axhline(noise_y, color="black")
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example

ValueErrorTraceback (most recent call last)
<ipython-input-54-d731671adbc0> in <module>
      1 fig, ax = plt.subplots()
      2 t = np.arange(model.loss_matrix_.shape[0])
----> 3 plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
      4 plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
      5 ax.axhline(noise_y, color="black")

<ipython-input-32-5428848ec3b9> in plot_aml_ci(ax, error, color, label, until_t)
     64         upper_ci[:until_t],
     65         color=color,
---> 66         alpha=0.2,
     67     )
     68

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs)
   1597     def inner(ax, *args, data=None, **kwargs):
   1598         if data is None:
-> 1599             return func(ax, *map(sanitize_sequence, args), **kwargs)
   1600
   1601         bound = new_sig.bind(ax, *args, **kwargs)

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/axes/_axes.py in fill_between(self, x, y1, y2, where, interpolate, step, **kwargs)
   5242             where = True
   5243         where = where & ~functools.reduce(np.logical_or,
-> 5244                                           map(np.ma.getmask, [x, y1, y2]))
   5245
   5246         x, y1, y2 = np.broadcast_arrays(np.atleast_1d(x), y1, y2)

ValueError: operands could not be broadcast together with shapes (100,) (50,)
#+end_example
#+attr_org: :width 373
[[file:./.ob-jupyter/103fb7ec7420207d6cce5711c631501957ac3b27.png]]
:END:

#+begin_src jupyter-python
zero_vs_ws = np.linalg.norm(test_ws, axis=1)
itl_vs_ws = np.linalg.norm(itl_rr.weights_ - test_ws, axis=1)
aml_w0_vs_ws = np.linalg.norm(model.w_0_[-1, :] - test_ws, axis=1)
aml_w_hat_vs_ws = np.linalg.norm(model.w_hat_[-1, :] - test_ws, axis=1)

fig, ax = plt.subplots(4, 1, sharex=True)
plot_hist_with_ci(zero_vs_ws, ax[0])
plot_hist_with_ci(itl_vs_ws, ax[1])
plot_hist_with_ci(aml_w0_vs_ws, ax[2])
plot_hist_with_ci(aml_w_hat_vs_ws, ax[3])
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 374
[[file:./.ob-jupyter/2abed047d4d8b833b186c4a41233e364e125efca.png]]
:END:

* Hypercube
:LOGBOOK:
CLOCK: [2020-05-14 Thu 15:12]--[2020-05-14 Thu 15:32] =>  0:20
CLOCK: [2020-05-13 Wed 16:14]--[2020-05-13 Wed 16:39] =>  0:25
CLOCK: [2020-05-12 Tue 20:26]--[2020-05-12 Tue 20:51] =>  0:25
CLOCK: [2020-05-12 Tue 14:41]--[2020-05-12 Tue 15:06] =>  0:25
CLOCK: [2020-05-12 Tue 14:10]--[2020-05-12 Tue 14:35] =>  0:25
:END:
All the data generated on the hypersphere.
#+begin_src jupyter-python
y_func_misspec = y_func_2nd_order

def generate_hypercube_data(
    d, noise_w, noise_y, k_shot, k_query, num_train_tasks=100, num_val_tasks=100, num_test_tasks=100
):
    env = HypercubeWithKVertexGaussian(d, k, 0.0)
    return generate_data(env, noise_w, noise_y, k_shot, k_query, num_train_tasks, num_val_tasks, num_test_tasks, y_func_misspec)

d = 2
k = 4
noise_w, noise_y = 0.0, 0.0
k_shot, k_query = 20, 25
n_tr, n_val, n_te = 50, 80, 100
train_tasks, train_tasks_kh, val_tasks, val_tasks_kh, test_tasks, test_tasks_kh = generate_hypersphere_data(d, noise_w, noise_y, k_shot, k_query, n_tr, n_val, n_te)
train_datasets = form_datasets_from_tasks(train_tasks)
val_datasets = form_datasets_from_tasks(val_tasks)
test_datasets = form_datasets_from_tasks(test_tasks)

train_ws = get_task_parameters(train_tasks)
val_ws = get_task_parameters(val_tasks)
test_ws = get_task_parameters(test_tasks)
#+end_src

#+RESULTS:

Plotting the weights
#+begin_src jupyter-python
fig, ax = plt.subplots(1, 1, figsize=(10, 10))
plot_task_weights(train_tasks, ax)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.axes._subplots.AxesSubplot at 0x7fc41ed91f90>
[[file:./.ob-jupyter/856c38ea75262164cc3762b2907ac80b37581b8d.png]]
:END:

Plot of the actual linear regression datasets generated. We pick 3 random tasks
which differ
#+begin_src jupyter-python
fig = plt.figure(figsize=(8, 16))
axes = [fig.add_subplot(3, 1, i, projection="3d") for i in range(1, 4)]
rand_idx = np.random.permutation(20)
for i, ax in enumerate(axes):
    task = train_tasks[rand_idx[i]]
    plot_task_lin_reg(task, ax)
    w = task["w"]
    ax.set_title("w: ({:.2f}, {:.2f})".format(w[0], w[1]))
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 460
[[file:./.ob-jupyter/87c3ef645f7750b2c1832c675143daadc28b02dc.png]]
:END:

From the above plot we can see how they differ, since we are assuming a linear
regression setup the points all lie on hyperspheres.

Now we consider how the different KH methods pick points.
#+begin_src jupyter-python
# KH on data
base_s2_D, meta_s2_D = calculate_double_gaussian_median_heuristics(
    train_datasets, n_base_subsamples=200
)
K_D = _gaussian_kernel_mmd2_matrix(
    A=train_datasets, B=train_datasets, base_s2=base_s2_D, meta_s2=meta_s2_D
)
# KH on weights
train_task_ws = get_task_parameters(train_tasks)
ws_dataset = train_task_ws[:, np.newaxis, :]
base_s2_w, meta_s2_w = calculate_double_gaussian_median_heuristics(
    ws_dataset, n_base_subsamples=200
)
K_w = _gaussian_kernel_mmd2_matrix(
    A=ws_dataset, B=ws_dataset, base_s2=base_s2_w, meta_s2=meta_s2_w
)
#+end_src

#+RESULTS:

Investigate how the kernel matrix look like.
#+begin_src jupyter-python
fig, ax = plt.subplots()
ax.imshow(K_D, vmin=0.0, vmax=1.0)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.image.AxesImage at 0x7fc41ef349d0>
#+attr_org: :width 252
[[file:./.ob-jupyter/1c268cd6dd93eec0ad95252645568b866371aa8e.png]]
:END:

#+begin_src jupyter-python
fig, ax = plt.subplots()
ax.imshow(K_w, vmin=0.0, vmax=1.0)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.image.AxesImage at 0x7fc41ec9c790>
#+attr_org: :width 252
[[file:./.ob-jupyter/74323a83c2cd15523c19af8215f9f3a32f628d87.png]]
:END:

#+begin_src jupyter-python
fig, ax = plt.subplots()
_ = ax.hist((K_w - K_D)[np.triu_indices(n_tr, k=1)], range=(-1.0, 1.0), density=True)
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 373
[[file:./.ob-jupyter/d4c159ccdbeae9a8bb56051b21b92db9c7675d1e.png]]
:END:

Looks pretty nice above, the weights and data dataset kernel matrix seem to find
something reasonable as the difference is not too unlike.

Running the actual kernel herding algorithms
#+begin_src jupyter-python
kh_D = KernelHerding(K_D)
kh_D.run()
kh_w = KernelHerding(K_w)
kh_w.run()
#+end_src

#+RESULTS:


#+begin_src jupyter-python
plot_kh_weights(kh_w, kh_D, train_tasks, until_t=20)
#+end_src

#+RESULTS:
:RESULTS:
: array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fc4240ef390>,
:        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc41ecbe310>,
:        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc41f11d750>],
:       dtype=object)
[[file:./.ob-jupyter/538468d240a4b87c43e34b5df15fb1f8ec121b17.png]]
:END:

** KNN Meta learning
:LOGBOOK:
CLOCK: [2020-05-13 Wed 17:48]--[2020-05-13 Wed 18:13] =>  0:25
:END:
We run KNN meta learning on the dataset to see and understand what works where.
We consider
- Uniform
- KH on data
- KH on weights
and we use the true weights. Alternatively, we will shrink the true weights to
see how that impacts (and possibly make it better than using the true weights).
This is due to the observed phenomenon where the ridge weights perform better
than the true weights.

Calculate the mmd distances from all the train to test tasks. These are used
later when we use the KNN algorithm
#+begin_src jupyter-python
train_datasets = form_datasets_from_tasks(train_tasks)
# Don't cheat, can only use support/train set for meta-test and meta-val
# tr_val_datasets = form_datasets_from_tasks(val_tasks, use_only_train=True)
tr_test_datasets = form_datasets_from_tasks(test_tasks, use_only_train=True)
# M_tr_val_D = np.sqrt(_mmd2_matrix(train_datasets, tr_val_datasets, base_s2_D))
M_tr_te_D = np.sqrt(_mmd2_matrix(train_datasets, tr_test_datasets, base_s2_D))
#+end_src

#+RESULTS:

We have two things to set, \(\alpha_{RR}, \alpha_{prot}\) for the regularisation
parameter in Ridge Regression and Prototypes.
#+begin_src jupyter-python
alpha_rrs = np.geomspace(1e-6, 3, 10)
alpha_prot = 0.001
#+end_src

#+RESULTS:

** ITL Ridge Reg
Evaluate ridge regression in an independent task learning setting
#+begin_src jupyter-python
rr = RidgeRegression(alpha=0.0001)
itl_rr = IndependentTaskLearning(train_tasks, rr)
itl_rr_opt_params, itl_rr_cross_val_loss = cross_validate_itl(
    itl_rr, {"alpha": alpha_rrs.tolist()}
)
itl_rr.set_params(itl_rr_opt_params)
itl_rr.tasks = test_tasks
itl_rr.calculate_transfer_risk()
#+end_src

#+RESULTS:
#+begin_example
2020-05-14 18:07:52.361 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 1e-06}
2020-05-14 18:07:52.415 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.14696106600289405
2020-05-14 18:07:52.416 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 1e-06}, with loss 0.1470
2020-05-14 18:07:52.417 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 5.244210785953468e-06}
2020-05-14 18:07:52.458 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.14696071829737267
2020-05-14 18:07:52.459 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 5.244210785953468e-06}, with loss 0.1470
2020-05-14 18:07:52.460 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 2.7501746767510743e-05}
2020-05-14 18:07:52.510 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.14695889501940254
2020-05-14 18:07:52.510 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 2.7501746767510743e-05}, with loss 0.1470
2020-05-14 18:07:52.511 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.0001442249570307409}
2020-05-14 18:07:52.553 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.14694933784875328
2020-05-14 18:07:52.555 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 0.0001442249570307409}, with loss 0.1469
2020-05-14 18:07:52.556 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.0007563460752642876}
2020-05-14 18:07:52.629 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.146899341113198
2020-05-14 18:07:52.630 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 0.0007563460752642876}, with loss 0.1469
2020-05-14 18:07:52.632 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.0039664382458145546}
2020-05-14 18:07:52.667 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.14664050149861013
2020-05-14 18:07:52.667 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 0.0039664382458145546}, with loss 0.1466
2020-05-14 18:07:52.668 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.02080083823051906}
2020-05-14 18:07:52.712 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.145371039292347
2020-05-14 18:07:52.713 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 0.02080083823051906}, with loss 0.1454
2020-05-14 18:07:52.714 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.10908398020536153}
2020-05-14 18:07:52.752 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.14063794629493953
2020-05-14 18:07:52.753 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 0.10908398020536153}, with loss 0.1406
2020-05-14 18:07:52.754 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 0.5720593855676914}
2020-05-14 18:07:52.803 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.13780440287099116
2020-05-14 18:07:52.804 | INFO     | __main__:cross_validate_itl:68 - Best params so far {'alpha': 0.5720593855676914}, with loss 0.1378
2020-05-14 18:07:52.807 | INFO     | __main__:cross_validate_itl:59 - Cross validating params: {'alpha': 3.0}
2020-05-14 18:07:52.872 | INFO     | __main__:cross_validate_itl:63 - Current loss: 0.1737162751291573
#+end_example

The train loss
#+begin_src jupyter-python
fig, ax = plt.subplots()
sns.distplot(itl_rr.losses_, kde=True, rug=True, ax=ax)
ax.axvline(itl_rr.losses_.mean(), color="red", linestyle="--")
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.lines.Line2D at 0x7fc41ec32ed0>
#+attr_org: :width 370
[[file:./.ob-jupyter/8393ce98ffa7641dee9eeb258437d9c687626fdc.png]]
:END:

** Meta-learning setup
:LOGBOOK:
CLOCK: [2020-05-13 Wed 18:49]--[2020-05-13 Wed 19:14] =>  0:25
:END:
Now we proceed to do active meta learning. We will reorder the sequences
according to KH on weights and data. As the actual meta learning algorithm we
will use the KNN on datasets and use the biased ridge regression. We will reuse
the optimal alpha from ITL with ridge reg. From here on we split into two cases,
where for the prototype estimator we use
- Ridge Regression
- True Weights

we use 3 for the number of nearest neighbours
#+begin_src jupyter-python
k_nn = 3
#+end_src

#+RESULTS:

*** Biased Ridge Reg
:LOGBOOK:
CLOCK: [2020-05-13 Wed 19:34]--[2020-05-13 Wed 19:59] =>  0:25
:END:
#+begin_src jupyter-python
aml_order = kh_D.sampled_order
biased_rr = BiasedRidgeRegression(alpha=itl_rr_opt_params["alpha"])
model = MetaKNNExperiment(
    train_tasks,
    test_tasks,
    M_tr_te_D,
    biased_rr,
    k_nn,
    aml_order,
    RidgeRegPrototypeEstimator(alpha=alpha_prot),
)
model.calculate_transfer_risk()
#+end_src

#+RESULTS:

Let's look at how this evolved over time, and compare it with the ITL baseline
#+begin_src jupyter-python
fig, ax = plt.subplots()
t = np.arange(model.loss_matrix_.shape[0])
plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
ax.axhline(noise_y, color="black")
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example

ValueErrorTraceback (most recent call last)
<ipython-input-71-d731671adbc0> in <module>
      1 fig, ax = plt.subplots()
      2 t = np.arange(model.loss_matrix_.shape[0])
----> 3 plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
      4 plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
      5 ax.axhline(noise_y, color="black")

<ipython-input-32-5428848ec3b9> in plot_aml_ci(ax, error, color, label, until_t)
     64         upper_ci[:until_t],
     65         color=color,
---> 66         alpha=0.2,
     67     )
     68

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs)
   1597     def inner(ax, *args, data=None, **kwargs):
   1598         if data is None:
-> 1599             return func(ax, *map(sanitize_sequence, args), **kwargs)
   1600
   1601         bound = new_sig.bind(ax, *args, **kwargs)

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/axes/_axes.py in fill_between(self, x, y1, y2, where, interpolate, step, **kwargs)
   5242             where = True
   5243         where = where & ~functools.reduce(np.logical_or,
-> 5244                                           map(np.ma.getmask, [x, y1, y2]))
   5245
   5246         x, y1, y2 = np.broadcast_arrays(np.atleast_1d(x), y1, y2)

ValueError: operands could not be broadcast together with shapes (100,) (50,)
#+end_example
#+attr_org: :width 394
[[file:./.ob-jupyter/1cea21a36b59706f4f0a159749448b0ea3cfb622.png]]
:END:

#+begin_src jupyter-python
zero_vs_ws = np.linalg.norm(test_ws, axis=1)
itl_vs_ws = np.linalg.norm(itl_rr.weights_ - test_ws, axis=1)
aml_w0_vs_ws = np.linalg.norm(model.w_0_[-1, :] - test_ws, axis=1)
aml_w_hat_vs_ws = np.linalg.norm(model.w_hat_[-1, :] - test_ws, axis=1)

fig, ax = plt.subplots(4, 1, sharex=True)
plot_hist_with_ci(zero_vs_ws, ax[0])
plot_hist_with_ci(itl_vs_ws, ax[1])
plot_hist_with_ci(aml_w0_vs_ws, ax[2])
plot_hist_with_ci(aml_w_hat_vs_ws, ax[3])
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 376
[[file:./.ob-jupyter/7b4c3eaf91b28421e58abf5b70541f34632f86be.png]]
:END:

I want to test the hypothesis of shrinkage. Let's compare the sizes of the
resulting \(w_{0}\) and \(\hat{w}\)
#+begin_src jupyter-python
fig, ax = plt.subplots()
ax.hist(np.linalg.norm(model.prototypes, axis=1))
#+end_src

#+RESULTS:
:RESULTS:
| array | ((19 16 7 5 1 1 1)) | array | ((0.13003616 0.73506237 1.34008858 1.94511479 2.550141 3.15516721 3.76019342 4.36521963)) | <a | list | of | 7 | Patch | objects> |
#+attr_org: :width 370
[[file:./.ob-jupyter/c86928a4d00c7c456f6c58eff09c185325219d7f.png]]
:END:

*** True weights
:LOGBOOK:
CLOCK: [2020-05-13 Wed 19:34]--[2020-05-13 Wed 19:59] =>  0:25
:END:
#+begin_src jupyter-python
aml_order = kh_D.sampled_order
biased_rr = BiasedRidgeRegression(alpha=itl_rr_opt_params["alpha"])
model = MetaKNNExperiment(
    train_tasks,
    test_tasks,
    M_tr_te_D,
    biased_rr,
    k_nn,
    aml_order,
    TrueWeightPrototypeEstimator(),
)
model.calculate_transfer_risk()
#+end_src

#+RESULTS:

Let's look at how this evolved over time, and compare it with the ITL baseline
#+begin_src jupyter-python
fig, ax = plt.subplots()
t = np.arange(model.loss_matrix_.shape[0])
plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
ax.axhline(noise_y, color="black")
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example

ValueErrorTraceback (most recent call last)
<ipython-input-75-d731671adbc0> in <module>
      1 fig, ax = plt.subplots()
      2 t = np.arange(model.loss_matrix_.shape[0])
----> 3 plot_aml_ci(ax, model.loss_matrix_, "blue", "aml", 100)
      4 plot_itl_ci(ax, itl_rr.losses_, "red", "itl", 100)
      5 ax.axhline(noise_y, color="black")

<ipython-input-32-5428848ec3b9> in plot_aml_ci(ax, error, color, label, until_t)
     64         upper_ci[:until_t],
     65         color=color,
---> 66         alpha=0.2,
     67     )
     68

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs)
   1597     def inner(ax, *args, data=None, **kwargs):
   1598         if data is None:
-> 1599             return func(ax, *map(sanitize_sequence, args), **kwargs)
   1600
   1601         bound = new_sig.bind(ax, *args, **kwargs)

~/anaconda3/envs/meta_learning/lib/python3.7/site-packages/matplotlib/axes/_axes.py in fill_between(self, x, y1, y2, where, interpolate, step, **kwargs)
   5242             where = True
   5243         where = where & ~functools.reduce(np.logical_or,
-> 5244                                           map(np.ma.getmask, [x, y1, y2]))
   5245
   5246         x, y1, y2 = np.broadcast_arrays(np.atleast_1d(x), y1, y2)

ValueError: operands could not be broadcast together with shapes (100,) (50,)
#+end_example
#+attr_org: :width 387
[[file:./.ob-jupyter/0c789ce60205e9402106f32635e93a5cbe8550fe.png]]
:END:

#+begin_src jupyter-python
zero_vs_ws = np.linalg.norm(test_ws, axis=1)
itl_vs_ws = np.linalg.norm(itl_rr.weights_ - test_ws, axis=1)
aml_w0_vs_ws = np.linalg.norm(model.w_0_[-1, :] - test_ws, axis=1)
aml_w_hat_vs_ws = np.linalg.norm(model.w_hat_[-1, :] - test_ws, axis=1)

fig, ax = plt.subplots(4, 1, sharex=True)
plot_hist_with_ci(zero_vs_ws, ax[0])
plot_hist_with_ci(itl_vs_ws, ax[1])
plot_hist_with_ci(aml_w0_vs_ws, ax[2])
plot_hist_with_ci(aml_w_hat_vs_ws, ax[3])
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 370
[[file:./.ob-jupyter/11e299f8e9da2c4966b70ebd00e14cd221d727df.png]]
:END:
